{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"Documentation for pynxtools-xps","text":"<p>pynxtools-xps is a free, and open-source data software for harmonizing X-ray photoelectron spectroscopy data and metadata for research data management using NeXus, implemented with the goal to make scientific research data FAIR (findable, accessible, interoperable and reusable).</p> <p>pynxtools-xps, which is a plugin for pynxtools, provides a tool for reading data from various proprietary and open data formats from technology partners and the wider XPS community and standardizing it such that it is compliant with the NeXus application definition <code>NXmpes</code> and <code>NXxps</code>, which is an extension of <code>NXmpes</code>. pynxtools-xps is developed both as a standalone reader and as a tool within NOMAD, which is the open-source data management platform for materials science we are developing with FAIRmat.</p> <p>pynxtools-xps solves the challenge of using heterogeneous and undocumented data formats which is common in X-ray Photoelectron Spectroscopy. In addition, it provides an interface for writing readers for different file formats to be mapped to NeXus.</p> <p>pynxtools-xps is useful for scientists from the XPS community that deal with heterogeneous data, for technology partners and data providers looking for ways to make their data FAIRer, and for research groups that want to organize their data using NeXus and NOMAD.</p>  Contact  <p>For questions or suggestions:</p> <ul> <li>Open an issue on the <code>pynxtools-xps</code> GitHub</li> <li>Join our Discord channel</li> <li>Get in contact with our lead developers.</li> </ul> Project and community <ul> <li>NOMAD code guidelines</li> </ul> <p>The work is funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - 460197019 (FAIRmat).</p>"},{"location":"index.html#tutorial","title":"Tutorial","text":"<p>A series of tutorials giving you an overview on how to store or convert your XPS data to NeXus compliant files.</p> <ul> <li>Installation guide</li> <li>Standalone usage</li> <li>How to use a NeXus/HDF5 file</li> <li>Usage in NOMAD</li> <li>Development guide</li> </ul>"},{"location":"index.html#how-to-guides","title":"How-to guides","text":"<p>How-to guides provide step-by-step instructions for a wide range of tasks, with the overarching topics:</p> <ul> <li>How to create your own reader for your XPS data</li> </ul>"},{"location":"index.html#learn","title":"Learn","text":"<p>The explanation section provides background knowledge on the implementation design, how the data is structured, how data processing can be incorporated, how the integration works in NOMAD, and more.</p> <ul> <li>Design principles and implementation</li> <li>NXmpes and NXxps</li> <li>The XPS coordinate system</li> <li>How to map raw XPS data to NeXus</li> <li>Mapping of data processing performed in CasaXPS</li> </ul>"},{"location":"index.html#reference","title":"Reference","text":"<p>Here you can learn which specific measurement setups and file formats from technology partners pynxtools-xps currently supports.</p> <p>The reader decides which data parser to use based on the file extension of the files provided. For the main XPS files, the following file extensions are supported:</p> <ul> <li>.ibw: Igor Binary Wave Format files, exported from Scienta Omicron</li> <li>.npl: VAMAS files, ISO standard data transfer format (ISO 14976), both in regular and irregular format</li> <li>.spe, .pro: Phi MultiPak files, proprietary format of PHI Electronics</li> <li>.sle: SpecsLabProdigy files, proprietary format of SPECS GmbH (1 and v4)</li> <li>.xml: SpecsLab 2files, XML format from SPECS GmbH (v1.6)</li> <li>.vms: VAMAS files, ISO standard data transfer format (ISO 14976), both in regular and irregular format</li> <li>.xy: SpecsLabProdigy export format in XY format (including all export settings)</li> <li>.txt:<ul> <li>exported by Scienta Omicron instruments</li> <li>exported by CasaXPS analysis software</li> </ul> </li> </ul> <p>You can find more information regarding the readers for data from different technology partners here:</p> <ul> <li>Data exported by SPECS spectrometers</li> <li>Data exported by Scienta Omicron spectrometers</li> <li>Data exported by Phi spectrometers</li> <li>VAMAS ISO Standard format</li> </ul>"},{"location":"contact.html","title":"Get in contact","text":"<p>NOMAD, <code>pynxtools</code>, and <code>pynxtools-xps</code> are open source project that warmly welcome community projects, contributions, suggestions, bug fixes, and constructive feedback. <code>pynxtools</code> is build mainly within FAIRmat Area B - Experiment.</p> <p>You can reach us through different channels. You can send an email directly to one of the main contributors:</p> Name E-mail Github profiles Dr. Lukas Pielsticker lukas.pielsticker@physik.hu-berlin.de @lukaspie <p>Alternatively, you can also:</p> <ul> <li>Open an issue on GitHub</li> <li>Join the NOMAD discord channel and ask us there directly.</li> </ul>"},{"location":"explanation/appdefs.html","title":"The NeXus application definitions: NXmpes and NXxps","text":""},{"location":"explanation/contextualization.html","title":"How to map raw XPS data to NeXus","text":"<p>Conceptually, mapping between representations of concepts and instance data is a key tasks in information science. The plugin pynxtools-xps implements this specifically for the file and serialization formats used within the research field of photoelectron spectroscopy (PES).</p> <p>In pynxtools-xps, the mapping from the vendor format is a two-step process:</p> <p>1) First, each information piece is parsed from the experiment- and vendor-specific and assigned a name that describes what the reader developer thinks it semantically means. This naming can come from documentation of the original data, existing key-value infrastructure in the data file, or from domain knowledge of the reader developer. All data and metadata items are internally stored as a flat list of dictionaries, with each dictionary containing all information about a single XP spectrum.</p> <p>2) This list of dicts is then mapped onto either the (NXmpes NeXus application definition or its specialization NXxps). For this, a JSON config file is used that provides a concept map from the originally assigned keys towards the groups, fields, and attributes in the NeXus standard. Such transformations are configured via the respective files in the config directory of pynxtools-xps.</p> <p>Upon parsing, the XPS reader uses the config file to map the (meta-)data to a template which follows the NeXus application definitions. It also takes metadata provided through additional means (i.e., an electronic lab notebook (ELN) file) to fill in missing required and recommended fields and attributes in the application definition that were not provided in the raw data files. It is this template variable from which core functions like convert.py of the pynxtools write the actual NeXus/HDF5 file. The latter tool is also referred to as the dataconverter of pynxtools.</p>"},{"location":"explanation/coordinate_system.html","title":"The XPS coordinate system","text":"<p>The application definition NXxps defines a coordinate system based on the sample stage, which is the same coordinate system as in the ISO standard for surface chemical analysis.</p> <p></p> <p>An example for this coordinate system can be found here.</p> <p>The file <code>config_vms_cs_fixed.json</code> contains a hard-coded measurement configuration, which was translated to <code>NXxps</code> using the following command:</p> <pre><code>user@box:~$ dataconverter config_vms_cs_fixed.json --reader xps --nxdl NXxps --ignore-undocumented --output vms-cs-fixed.nxs \n</code></pre> <p>The file <code>vms-cs.glb</code> contains a 3D representation (in gltf/glb format) of the NXtransformation matrices in the NeXus file. It was created using the nexus3d tool with the following command (using the STL objects located in the <code>shapes/</code> subfolder):</p> <pre><code>user@box:~$ uv pip install nexus3d\nuser@box:~$ python shapes/shapes.py\nuser@box:~$ nexus3d vms-cs-fixed.nxs -fo vms-cs.glb --blender -c config-stl.json -s 1\n</code></pre>"},{"location":"explanation/data_processing.html","title":"Data processing with CasaXPS","text":"<p><code>pynxtools-xps</code> supports extracting data and the description of the data analysis (i.e., peak fitting) by the CasaXPS data analysis software.</p>"},{"location":"explanation/data_processing.html#modeling-of-peak-fitting-in-casaxps","title":"Modeling of peak fitting in CasaXPS","text":"<p>This is a short description of how peak models are implemented in CasaXPS. The user is referred to the CasaXPS web site for a more accurate and detailed explanation.</p> <p>CasaXPS models peak fitting using two concepts: regions and components. Regions define the energy range that is used for peak fitting as well as the background shape to be used. Many different background shapes are available in CasaXPS, including the most commonly used linear, Shirley, and Tougaard backgrounds. Each peak model is made up of several components, each of which model a single chemical species. Components can have many different line shapes. Constraints with respect to the total area, full-width at half maximum, and position on the energy axis can be defined as well, also with respect to any of the other components.</p>"},{"location":"explanation/data_processing.html#modeling-of-data-fitting-in-nexus","title":"Modeling of data fitting in NeXus","text":"<p>NeXus contains a base class for modelling fit procedures called <code>NXfit</code>. <code>NXfit</code> contains</p> <ul> <li>the data to be modelled</li> <li>one or more instances of <code>NXpeak</code> to define individual peaks in the model. These map to the components in CasaXPS</li> <li>one or more instances of <code>NXpeak</code> to define the background to be subtracted during the fit. These map to the regions in CasaXPS.</li> <li>two instances of <code>NXfit_function</code> to describe the function used for the global fit (<code>global_fit_function</code>) and for the optimization (<code>error_function</code>).</li> <li>information about the fitting sum (envelope) and the residual of the fit</li> </ul> <p>The application definition <code>NXxps</code> implements an <code>NXfit</code> group to model peak fitting in XPS. Aside from the terms defined in the base class <code>NXfit</code>, it also contains some information more specific to XPS fits, like the atomic concentration of each species in the fit model.</p>"},{"location":"explanation/data_processing.html#how-to-convert-peak-fitting-in-casaxps-into-a-nexus-file","title":"How-to convert peak fitting in CasaXPS into a NeXus file","text":"<p><code>pynxtools-xps</code> can extract the definition of the peak fitting parameters and store them in an HDF5 file compliant with the <code>NXxps</code> application definition.</p> <p>Three files are needed for the example conversion:</p> <p>1) The VAMAS (.vms) file containing the original (meta)data and the definition of the peak fitting in the VAMAS comments 2) The lineshapes of the measurement data as well as the peak fitting, exported from CasaXPS as a TXT file. This file can be obtained by using the <code>Save Tab ASCII</code> to TXT button in CasaXPS and choosing \"Rows of Tables\" as the export option. 3) The analysis results (incl. the atomic concentrations), exported from CasaXPS as a CSV file. This file can be obtained from the <code>Quantify</code> window in CasaXPS and exporting the \"Comps\" report from the \"Report\" tab. You can learn more about XPS quantification in CasaXPS here.</p> <p>You can have a look a the example conversion to understand which exported files are expected for the data reader to work.</p>"},{"location":"explanation/data_processing.html#example-conversion","title":"Example conversion","text":"<p>See here for an example of converting VAMAS data containing data analysis results from CasaXPS. The resulting file looks like this:</p> <p></p>"},{"location":"explanation/implementation.html","title":"Purpose and aim of pynxtools-xps","text":"<p>pynxtools-xps aims for the implementation of FAIR principles of data stewardship in photoelectron spectroscopy (PES). In many experimental fields, there has been a push towards such standardization and interoperability in recent years; however, there has been a distinct lack of such efforts in PES.</p> <p>While there exists a widely adopted ISO standard for data transfer in surface chemical analysis, it does not fully cover all of the information that is obtained in modern photoemission experiments. Within the FAIRmat project of the German National Research Data Infrastructure Germany (NFDI), we have spent considerable effort towards building developing an extensive and elaborated standard (NXmpes with its specialization NXxps) for harmonizing PES data using NeXus, a community-driven data-modeling framework for experiments.</p> <p>The goal of pynxtools-xps is to provide a mapping from the diverse proprietary and open-source software solutions used in the XPS community towards this NeXus standard. The software implements a suggestion how diverse (meta)data from the research field of photoelectron spectroscopy can be parsed and normalized to enable users to compare data. The software can parse data provided by many different data providers and frequently used serialization and formatting. This data is then mapped onto the NeXus standard.</p> <p>As part of pynxtools and its plugin infrastructure, pynxtools-xps is fully integrated into the NOMAD research data management systems (RDMS), with the aim of facilitating harmonization of XPS data and enabling development of data-centric software tools and services.</p>"},{"location":"explanation/implementation.html#software-landscape-in-photoelectron-spectroscopy-a-mixture-of-proprietary-and-open-source-solutions","title":"Software landscape in photoelectron spectroscopy - a mixture of proprietary and open-source solutions","text":"<p>As in many other experimental fields, the software landscape in photoelectron spectroscopy is extremely diverse, ranging from fully integrated software solution from technology partners, that integrate the measurement, post-processing, and data analysis, to custom-written software for specific uses cases. While proprietary software is often easy to use for end users, such software often writes to proprietary serialization formats (file or database entries). Not only are these formats not openly readable, but they are often not well-documented and the content and meaning of the semantic concepts is very often not documented publicly. While open-source software typically writes to more openly (and sometimes better documented) formats, they tend to loose much of the metadata that commercial vendors can provide with their data. pynxtools-xps aims at both endpoints of this spectrum and everything in-between: it provides an easy-to-use framework for writing a standardization parser for small, encapsulated solutions, while also providing the possibility of mapping the full richness of data and metadata acquired in a high-end XPS laboratory onto NeXus.</p>"},{"location":"explanation/implementation.html#implementation-design","title":"Implementation design","text":"<p>pynxtools-xps is a community-based tool that provides a bottom-up approach for mapping XPS data onto the NXmpes and NXxps standards. Specifically, the software contains example parsers for data that was measured by PES researchers in a wide array of experimental setups. The goal is not necessarily to implement a fully comprehensive mapping of all possible existing file formats, but rather help the individual researcher or technology partner to start reading their data into the NeXus standard.</p> <p>Therefore, the following design patterns guide our implementation:</p> <ul> <li>We do not consider that our work is complete (from the perspective of the idea in mind that a user can expect to drag-and-drop arbitrary content).</li> <li>We consider ontology matching a team effort that can only be achieved with technology partners and scientists working together.</li> <li>Our work is open to suggestions by the PES community, always realizing that just being able to read from a specific file alone is not solving the challenge that pynxtools-xps addresses.</li> <li>We provide specific tangible examples of (meta)data semantic mapping for specific file formats that are frequently used in XPS. These include the main formats of the leading vendors of PES spectrometers.</li> <li>The tool itself is build such that is easily extendable.</li> <li>The goal is to continuously grow the number of parsers available for different communities. We therefore encourage researchers and technology partners to get in contact in order to get started with standardization in NeXus and NOMAD.</li> </ul>"},{"location":"explanation/nomad_integration.html","title":"NOMAD integration","text":""},{"location":"how-tos/build_a_reader.html","title":"How to build your own reader","text":"<p>Your current data is not supported yet? Don't worry, the following how-to will guide you how to write a reader your own data.</p>"},{"location":"how-tos/build_a_reader.html#pynxtools-xps-supports-your-format-but-some-groups-and-fields-are-different","title":"pynxtools-xps supports your format, but some groups and fields are different","text":"<p>Good! The basic functionality to read your data is already in place. Before you start writing your own reader, consider two options: 1) You can modify the default config files. 2) Consider opening a pull request on the GitHub repository modifying the existing reader.</p>"},{"location":"how-tos/build_a_reader.html#you-have-a-completely-new-data-format","title":"You have a completely new data format","text":"<p>You will have to write a new sub-reader inside pynxtools-xps. There are multiple steps to get started:</p>"},{"location":"how-tos/build_a_reader.html#development-install","title":"Development install","text":"<p>You should start with a development install of the package with its dependencies:</p> <pre><code>git clone https://github.com/FAIRmat-NFDI/pynxtools-xps.git \\\\\n    --branch main \\\\\n    --recursive pynxtools_xps\ncd pynxtools_xps\npython -m pip install --upgrade pip\npython -m pip install -e .\npython -m pip install -e \".[dev,consistency_with_pynxtools]\"\n</code></pre> <p>There is also a pre-commit hook available which formats the code and checks the linting before actually committing. It can be installed with <pre><code>pre-commit install\n</code></pre> from the root of this repository.</p>"},{"location":"how-tos/build_a_reader.html#design-strategy","title":"Design strategy","text":"<p>The development process is modular so that new parsers can be added. The design logic is the following: 1. First, <code>XpsDataFileParser</code> selects the proper parser based on the file extensions of the provided files. It then calls a sub-parser that can read files with such extensions and calls the <code>parse_file</code> function of that reader. In addition, it selects a proper config file from the <code>config</code> subfolder. 2. Afterwards, the NXmpes NXDL template is filled with the data in <code>XpsDataFileParser</code> using the <code>config</code> file. Data that is not in the given main files can be added through the ELN file (and must be added for required fields in NXmpes).</p>"},{"location":"how-tos/build_a_reader.html#write-your-reader","title":"Write your reader","text":"<p>TODO!</p>"},{"location":"how-tos/build_a_reader.html#test-the-software","title":"Test the software","text":"<p>There exists a basic test framework written in pytest which can be used as follows: <pre><code>python -m pytest -sv tests\n</code></pre> You should add test data and add your reader to the <code>test_params</code> in the <code>test_reader.py</code> script.</p>"},{"location":"how-tos/build_a_reader.html#further-details","title":"Further details","text":"<p>NXmpes</p> <p>NXxps</p>"},{"location":"reference/phi.html","title":"Data from Phi VersaProbe 4 instruments","text":"<p>The reader supports Phi MultiPak .spe (single spectra) and .pro (sputter profile / external parameter scan / ....) files, which is the proprietary format of PHI Electronics used for their VersaProbe 4 instruments. The Phi MultiPak software version that was used to measure this data is SS 3.3.3.2.1. </p> <p>The reader for the Phi data can be found here.</p>"},{"location":"reference/phi.html#spe-data-single-spectrum","title":".spe data (single spectrum):","text":"<p>Example data for this file format is available here.</p> <p>The example conversion can be run with the following command: <pre><code>user@box:~$ dataconverter SnO2_10nm.spe eln_data_phi.yaml --reader xps --nxdl NXxps --output SnO2_10nm.spe.nxs\n</code></pre></p>"},{"location":"reference/phi.html#pro-data-profiling","title":".pro data (profiling):","text":"<p>Example data for this file format is available here.</p> <p>The example conversion can be run with the following command:</p> <pre><code>user@box:~$ dataconverter SnO2_10nm_1.pro eln_data_phi.yaml --reader xps --nxdl NXxps --output SnO2_10nm_1.pro.nxs\n</code></pre>"},{"location":"reference/phi.html#acknowledgments","title":"Acknowledgments","text":"<p>We thank Sebastian Benz and Dr. Joachim Sann from Justus-Liebig-Universit\u00e4t Gie\u00dfen for providing these example data sets.</p>"},{"location":"reference/scienta.html","title":"Data from Scienta Omicron instruments","text":"<p>The reader supports reading data exported as .txt from Scienta Omicron Scienta Omicron instruments, both as .txt as well as Igor Binary Wave Format files.</p> <p>The reader for the Scienta data can be found here.</p>"},{"location":"reference/scienta.html#txt-data","title":".txt data","text":"<p>Example data for the Scienta .txt reader is available here.</p> <p>The example conversion for the .txt exports can be run with the following command.</p> <pre><code>user@box:~$ dataconverter Cu-HHTP_*.txt eln_data_scienta_txt.yaml --reader xps --nxdl NXxps --output Cu-HHTP.txt.nxs\n</code></pre>"},{"location":"reference/scienta.html#ibw-data","title":".ibw data","text":"<p>Example data for the Scienta .ibw reader is available here.</p> <p>The example conversion for the .ibw (Igor binary wave format) data can be run with the following command.</p> <pre><code>user@box:~$ dataconverter Cu-HHTP_*.ibw eln_data_scienta_ibw.yaml --reader xps --nxdl NXxps --output Cu-HHTP.ibw.nxs\n</code></pre>"},{"location":"reference/scienta.html#acknowledgments","title":"Acknowledgments","text":"<p>We thank Dr. Alexei Nefedov from KIT for providing the example data sets.</p>"},{"location":"reference/specs.html","title":"Data from SPECS instruments","text":"<p>The reader supports SpecsLabProdigy files, which is the proprietary format of SPECS GmbH. Currently, the following file extensions are supported:</p> <ul> <li>.sle: SpecsLabProdigy file software version: v1.6, &gt;v4)</li> <li>.xml: SpecsLab 2files, XML format from SPECS GmbH (software version: v4.63 tested, other versions also work)</li> <li>.xy: SpecsLabProdigy export format in XY format (including all export settings)</li> </ul> <p>The readers for the SPECS data can be found here.</p>"},{"location":"reference/specs.html#sle-data","title":".sle data","text":"<p>Example data for the SLE reader is available here.</p> <p>The example conversion can be run with the following command. <pre><code>user@box:~$ dataconverter --params-file params.yaml\n</code></pre></p> <p>Note that the <code>params.yaml</code> file contains the <code>remove_align</code> keyword which is special for the SLE parser. It allows removal of alignment spectra that were taken during the experiment. For this example, it considerably speeds up the conversion</p>"},{"location":"reference/specs.html#xml-data","title":".xml data","text":"<p>Example data for the SPECS XML reader is available here.</p> <p>The example conversion can be run with the following command. <pre><code>user@box:~$ dataconverter In-situ_PBTTT_XPS_SPECS.xml eln_data_xml.yaml --reader xps --nxdl NXxps --output In-situ_PBTTT.nxs\n</code></pre></p>"},{"location":"reference/specs.html#xy-data","title":".xy data","text":"<p>Example data for the SPECS XY reader is available here.</p> <p>The example conversion can be run with the following command. <pre><code>user@box:~$ dataconverter MgFe2O4.xy eln_data_xy.yaml --reader xps --nxdl NXxps --output MgFe2O4.nxs\n</code></pre></p>"},{"location":"reference/vms.html","title":"VAMAS ISO standard (VMS)","text":"<p>The reader supports VAMAS (.vms, .npl) files, the ISO standard data transfer format (ISO 14976) for X-ray photoelectron spectroscopy. The data can be stored both in REGULAR (i.e, with an equally spaced energy axis) as well as IRREGULAR mode. The reader also allows for .npl files which are structured in the same way as .vms files.</p> <p>Note that most vendors and analysis software tend to write metadata from their instruments into the comment lines of the VAMAS format. Currently, the VAMAS reader supports parsing of metadata from VAMAS format for the following vendors and software solutions:</p> <ul> <li>Kratos Analytical Ltd</li> <li>Specs GmbH</li> <li>Phi Electronics: same metadata as in the PHI reader</li> <li>CasaXPS: calibrations and peak fitting</li> </ul> <p>The reader for the VAMAS format can be found here.</p>"},{"location":"reference/vms.html#standard-vms-data","title":"Standard .vms data","text":"<p>Example data is available here. The data was measured with and exported from SpecsLabProdigy.</p>"},{"location":"reference/vms.html#regular-file-format","title":"REGULAR file format","text":"<p>The example conversion for the REGULAR VAMAS file can be run with the following command:</p> <pre><code>user@box:~$ dataconverter regular.vms eln_data_vms.yaml --reader xps --nxdl NXxps --output regular.vms.nxs \n</code></pre>"},{"location":"reference/vms.html#irregular-file-format","title":"IRREGULAR file format","text":"<p>The example conversion for the IRREGULAR VAMAS file can be run with the following command:</p> <pre><code>user@box:~$ dataconverter irregular.vms eln_data_vms.yaml --reader xps --nxdl NXxps --output irregular.vms.nxs\n</code></pre>"},{"location":"reference/vms.html#data-analysis-and-peak-fitting","title":"Data analysis and peak fitting","text":"<p><code>pynxtools-xps</code> also supports extracting data and the description of the data analysis (i.e., peak fitting) by the CasaXPS data analysis software. Three files are needed for the example conversion:</p> <p>1) The VAMAS (.vms) file containing the original (meta)data and the definition of the peak fitting in the VAMAS comments 2) The lineshapes of the measurement data as well as the peak fitting, exported from CasaXPS as a TXT file. 3) The analysis results (incl. the atomic concentrations), exported from CasaXPS as a CSV file.</p> <p>Example data is available here.</p> <p>The example conversion for the .txt export file can be run with the following command:</p> <pre><code>user@box:~$ dataconverter FeO* eln.yaml --reader $READER --nxdl $NXDL --output vms_analysis_ref.nxs\n</code></pre> <p>You can learn much more about how to prepare the data in CasaXPS for NeXus conversion here.</p>"},{"location":"reference/vms.html#standalone-export-from-casaxps","title":"Standalone export from CasaXPS","text":"<p><code>pynxtools-xps</code> also supports data exported from CasaXPS as TXT file by itself.</p> <p>Example data is available here.</p> <p>The example conversion for the .txt export file can be run with the following command:</p> <pre><code>user@box:~$ dataconverter vms_txt_export.txt eln_data_vms_txt_export.yaml --reader xps --nxdl NXxps --output vms_txt_export.nxs\n</code></pre>"},{"location":"tutorial/contributing.html","title":"Development guide","text":"<p>This tutorial will guide you through on how to set up a working environment for developing <code>pynxtools-xps</code>.</p>"},{"location":"tutorial/contributing.html#what-should-you-know-before-this-tutorial","title":"What should you know before this tutorial?","text":"<ul> <li>You should read the guide on getting started with <code>pynxtools</code>.</li> <li>You should read the installation tutorial.</li> </ul>"},{"location":"tutorial/contributing.html#what-you-will-know-at-the-end-of-this-tutorial","title":"What you will know at the end of this tutorial?","text":"<p>You will know</p> <ul> <li>how to setup your environment for developing <code>pynxtools-xps</code></li> <li>how to make changes to the software</li> <li>how to test the software</li> <li>how to contribute on GitHub</li> <li>how to use <code>pynxtools-xps</code> as a NOMAD plugin</li> </ul>"},{"location":"tutorial/contributing.html#contributing","title":"Contributing","text":"Structure of the <code>pynxtools-xps</code> repository <p>The software tools are located inside <code>src/pynxtools_xps</code>. They are shipped with unit tests located in <code>tests</code>.</p>"},{"location":"tutorial/contributing.html#setup","title":"Setup","text":"<p>It is recommended to use python 3.12 with a dedicated virtual environment for this package. Learn how to manage python versions and virtual environments. We recommend using <code>uv</code>, an extremely fast Python package and project manager. In this tutorial, you will find parallel descriptions, using either <code>uv</code> or a more classical approach using <code>venv</code> and <code>pip</code>.</p> <p>Start by creating a virtual environment:</p> uvvenv <p><code>uv</code> is capable of creating a virtual environment and install the required Python version at the same time.</p> <pre><code>uv venv --python 3.12\n</code></pre> <p>Note that you will need to install the Python version manually beforehand.</p> <pre><code>python -m venv .venv\n</code></pre> <p>That command creates a new virtual environment in a directory called .venv.</p>"},{"location":"tutorial/contributing.html#development-installation","title":"Development installation","text":"<p>We start by cloning the repository:</p> <pre><code>git clone https://github.com/FAIRmat-NFDI/pynxtools-xps.git \\\\\n    --branch main \\\\\n    --recursive pynxtools-xps\ncd pynxtools-xps\n</code></pre> <p>Next, we install the package in editable mode (together with its dependencies):</p> uvpip <pre><code>uv pip install -e \".[dev]\"\n</code></pre> <p>Note that you will need to install the Python version manually beforehand.</p> <pre><code>pip install --upgrade pip\npip install -e \".[dev]\"\n</code></pre>"},{"location":"tutorial/contributing.html#linting-and-formatting","title":"Linting and formatting","text":"<p>We are using ruff and mypy for linting, formatting, and type checking. It is recommended to use the pre-commit hook available for ruff which formats the code and checks the linting before making a Git commit.</p> <p>Install the precommit by running</p> <pre><code>pre-commit install\n</code></pre> <p>from the root of this repository.</p>"},{"location":"tutorial/contributing.html#testing","title":"Testing","text":"<p>There exist unit tests for the software written in pytest which can be used as follows:</p> <pre><code>pytest -sv tests\n</code></pre>"},{"location":"tutorial/contributing.html#editing-the-documentation","title":"Editing the documentation","text":"<p>We are using `mkdocs for the documentation. If you edit the documentation, you can build it locally. For this, you need to install an additional set of dependencies:</p> uvpip <pre><code>uv pip install -e \".[docs]\"\n</code></pre> <pre><code>pip install -e \".[docs]\"\n</code></pre> <p>You can then serve the documentation locally by running</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"tutorial/contributing.html#contributing-to-the-package-on-github","title":"Contributing to the package on GitHub","text":"<p>Once you are happy with the changes, please commit them on a separate branch and create a pull request on GitHub. We run a number of GitHub actions that check the correct linting, run the tests in an isolated environment, and build the documentation. Once these pass and a peer review of the code has occurred, your code will be accepted.</p>"},{"location":"tutorial/contributing.html#developing-pynxtools-xps-as-a-nomad-plugin","title":"Developing <code>pynxtools-xps</code> as a NOMAD plugin","text":"<p>If you plan to contribute to the NOMAD plugin functionality of pynxtools-xps, it often makes sense to use the NOMAD development environment called <code>nomad-distro-dev</code>. You can learn more in the NOMAD documentation.</p>"},{"location":"tutorial/contributing.html#troubleshooting","title":"Troubleshooting","text":"<p>If you face any issues with the tool or when setting up the development environment, please create a new Github Issue.</p>"},{"location":"tutorial/installation.html","title":"Installation guide","text":""},{"location":"tutorial/installation.html#what-should-you-know-before-this-tutorial","title":"What should you know before this tutorial?","text":"<p>To get started, it does not hurt to read the following <code>pynxtools</code> tutorial:</p> <ul> <li>Guide on getting started with <code>pynxtools</code>, NeXus, and NOMAD</li> <li>Installation tutorial for <code>pynxtools</code></li> </ul>"},{"location":"tutorial/installation.html#what-you-will-know-at-the-end-of-this-tutorial","title":"What you will know at the end of this tutorial?","text":"<p>You will know</p> <ul> <li>how to install <code>pynxtools-xps</code></li> <li>how to install <code>pynxtools-xps</code> together with NOMAD</li> </ul>"},{"location":"tutorial/installation.html#setup","title":"Setup","text":"<p>It is recommended to use python 3.12 with a dedicated virtual environment for this package. Learn how to manage python versions and virtual environments.</p> <p>There are many alternatives to managing virtual environments and package dependencies (requirements). We recommend using <code>uv</code>, an extremely fast Python package and project manager. In this tutorial, you will find parallel descriptions, using either <code>uv</code> or a more classical approach using <code>venv</code> and <code>pip</code>.</p> <p>Start by creating a virtual environment:</p> uvvenv <p><code>uv</code> is capable of creating a virtual environment and install the required Python version at the same time.</p> <pre><code>uv venv --python 3.12\n</code></pre> <p>Note that you will need to install the Python version manually beforehand.</p> <pre><code>python -m venv .venv\n</code></pre> <p>That command creates a new virtual environment in a directory called <code>.venv</code>.</p>"},{"location":"tutorial/installation.html#installation","title":"Installation","text":"<p>Install the latest stable version of this package from PyPI with</p> uvpip <pre><code>uv pip install pynxtools-xps\n</code></pre> <pre><code>pip install pynxtools-xps\n</code></pre> <p>You can also install the latest development version with</p> uvpip <pre><code>uv pip install git+https://github.com/FAIRmat-NFDI/pynxtools-xps.git\n</code></pre> <pre><code>pip install git+https://github.com/FAIRmat-NFDI/pynxtools-xps.git\n</code></pre>"},{"location":"tutorial/installation.html#how-to-install-pynxtools-xps-with-nomad","title":"How to install <code>pynxtools-xps</code> with NOMAD","text":"<p>To use <code>pynxtools-xps</code> with NOMAD, simply install it in the same environment as the <code>nomad-lab</code> package. NOMAD will recognize <code>pynxtools-xps</code> as a plugin automatically. In addition, NOMAD will install a schema for NeXus application definitions.</p>"},{"location":"tutorial/installation.html#start-using-pynxtools-xps","title":"Start using <code>pynxtools-xps</code>","text":"<p>That's it! You can now use <code>pynxtools-xps</code>!</p>"},{"location":"tutorial/nexusio.html","title":"How to use a NeXus/HDF5 file","text":""},{"location":"tutorial/nomad.html","title":"Convert data to NeXus using NOMAD Oasis","text":"<p>You not only want to use pynxtools-xps as a standalone, but also use a more comprehensive research data management system. NOMAD is a great choice to make it easier than ever to work with your research data. At this point you are probably have an idea of what FAIR data is. Even if you don't, it doesn't matter. NOMAD provides a simple graphical interface that let's you collect and have your data ready for publication.</p>"},{"location":"tutorial/nomad.html#steps","title":"Steps","text":"<p>Go to <code>Publish -&gt; Uploads</code></p> <p>TODO: add the correct steps</p>"},{"location":"tutorial/standalone.html","title":"Convert X-ray spectroscopy data and metadata to NeXus","text":""},{"location":"tutorial/standalone.html#who-is-this-tutorial-for","title":"Who is this tutorial for?","text":"<p>This document is for people who want to use this reader as a standalone standardize their research data by converting these into a NeXus standardized format.</p>"},{"location":"tutorial/standalone.html#what-should-you-should-know-before-this-tutorial","title":"What should you should know before this tutorial?","text":"<ul> <li>You should have a basic understanding of FAIRmat NeXus and pynxtools</li> <li>You should have a basic understanding of using Python and Jupyter notebooks via JupyterLab</li> </ul>"},{"location":"tutorial/standalone.html#what-you-will-know-at-the-end-of-this-tutorial","title":"What you will know at the end of this tutorial?","text":"<p>You will have a basic understanding how to use pynxtools-xps for converting your XPS data to a NeXus/HDF5 file.</p>"},{"location":"tutorial/standalone.html#steps","title":"Steps","text":""},{"location":"tutorial/standalone.html#installation","title":"Installation","text":"<p>See here for how to install pynxtools together with the XPS reader plugin.</p>"},{"location":"tutorial/standalone.html#running-the-reader-from-the-command-line","title":"Running the reader from the command line","text":"<p>An example script to run the XPS reader in <code>pynxtools</code>:</p> <pre><code>user@box:~$ dataconverter $&lt;xps-file path&gt; $&lt;xps-file path&gt; $&lt;eln-file path&gt; --reader xps --nxdl NXxps --output &lt;output-file path&gt;.nxs\n</code></pre> <p>Note that none of the supported file format have data/values for all required and recommended fields and attributes in <code>NXxps</code>. In order for the validation step of the XPS reader to pass, you need to provide an ELN file that contains the missing values.</p>"},{"location":"tutorial/standalone.html#examples","title":"Examples","text":"<p>You can find examples how to use <code>pynxtools-xps</code> for your XPS research data pipeline in <code>src/pynxtools-xps/nomad/examples](https://github.com/FAIRmat-NFDI/pynxtools-xps/tree/main/src/pynxtools_xps/nomad/examples/). These are designed for working with [</code>NOMAD<code>](https://nomad-lab.eu/) and its [</code>NOMAD Remote Tools Hub (NORTH)`. Feel invited to try out the respective tutorial.</p> <p>There are also small example files with raw and converted data for using the <code>pynxtools</code> dataconverter with the <code>mpes</code> reader and the <code>NXmpes</code> application definition in the <code>examples</code> folder.</p> <p>For this tutorial, we will work with the example data for the VAMAS reader (see here). You can run the conversion as</p> <pre><code>dataconverter \\\\\n    --reader xps \\\\\n    --nxdl NXmpes \\\\\n    regular.vms \\\\\n    eln_data_vms.yaml \\\\\n    -c  config_file.json \\\\\n    --output regular.vms.nxs \n</code></pre> <p>TODO: add more steps! </p> <p>Congrats! You now have a FAIR NeXus file!</p>"}]}